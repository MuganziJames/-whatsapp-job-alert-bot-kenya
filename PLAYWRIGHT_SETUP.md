# üöÄ Playwright Job Scraping Implementation Guide

## Overview

This guide shows how to implement browser automation using Playwright to reliably scrape jobs from JavaScript-heavy Kenyan job sites.

## Why Playwright Over requests + BeautifulSoup?

### Current Problems (from your logs):

- **HTTP 403 errors**: Sites like Fuzu are blocking requests
- **0 job elements found**: Sites load content with JavaScript after page load
- **Anti-detection**: Modern sites detect and block automated requests

### Playwright Solutions:

- **Real browser**: Uses actual Chromium browser, not detectable as bot
- **JavaScript execution**: Waits for dynamic content to load
- **Anti-detection**: Realistic browser behavior and headers
- **Modern**: Built specifically for modern web applications

## Installation Steps

### 1. Install Playwright

```bash
pip install playwright==1.40.0
```

### 2. Install Browser Binaries

```bash
playwright install
```

### 3. Verify Installation

```bash
python test_playwright.py
```

## Implementation Architecture

### 1. **Enhanced Site Configuration**

```python
JOB_SITES_PLAYWRIGHT = {
    'brightermonday': {
        'base_url': 'https://www.brightermonday.co.ke',
        'search_url': 'https://www.brightermonday.co.ke/jobs',
        'job_selectors': ['[data-testid="job-card"]', '.job-item'],
        'title_selectors': ['[data-testid="job-title"]', '.job-title'],
        'wait_for': '.job-item, [data-testid="job-card"]'
    }
}
```

### 2. **Browser Automation Flow**

```
1. Launch headless Chromium browser
2. Create realistic browser context (viewport, headers, user-agent)
3. Navigate to job site
4. Wait for JavaScript content to load
5. Extract job data using CSS selectors
6. Close browser and return results
```

### 3. **Anti-Detection Features**

- **Realistic headers**: Accept-Language, User-Agent, etc.
- **Human-like delays**: Random waits between actions
- **Browser fingerprinting**: Remove webdriver properties
- **Viewport simulation**: Desktop browser dimensions

## Key Features

### ‚úÖ **Concurrent Scraping**

- All 4 sites scraped simultaneously
- ~10-15 second total scraping time
- Parallel browser instances

### ‚úÖ **Smart Fallback System**

```
1. Try Playwright (modern sites)
2. Fallback to requests (simple sites)
3. Use mock data (if all fails)
```

### ‚úÖ **Robust Error Handling**

- Timeout protection (30s per site)
- Exception handling per site
- Graceful degradation

### ‚úÖ **Enhanced Job Extraction**

- Multiple CSS selector fallbacks
- Company name extraction
- Location detection
- Link normalization

## Performance Comparison

| Method                   | Speed           | Success Rate  | JavaScript Support |
| ------------------------ | --------------- | ------------- | ------------------ |
| requests + BeautifulSoup | Fast (3-5s)     | Low (0-20%)   | ‚ùå No              |
| Playwright               | Medium (10-15s) | High (70-90%) | ‚úÖ Yes             |

## Usage Examples

### Basic Usage

```python
from scraper_playwright import scrape_jobs_enhanced

jobs = scrape_jobs_enhanced('software engineering')
print(f"Found {len(jobs)} jobs")
```

### Integration with Bot

```python
# In bot.py
from scraper_playwright import scrape_jobs as scrape_jobs_playwright

# Replace existing scraper import
jobs = scrape_jobs_playwright(user['interest'])
```

## Site-Specific Configurations

### 1. **BrighterMonday**

- **Challenge**: React-based job listings
- **Solution**: Wait for `[data-testid="job-card"]` elements
- **Selectors**: Modern data-testid attributes

### 2. **Fuzu**

- **Challenge**: Heavy JavaScript, 403 blocks requests
- **Solution**: Full browser simulation with realistic headers
- **Selectors**: `.job-card`, `.job-item` fallbacks

### 3. **MyJobMag**

- **Challenge**: Dynamic content loading
- **Solution**: Wait for `.job-item` elements to appear
- **Selectors**: Traditional class-based selectors

### 4. **Corporate Staffing**

- **Challenge**: Custom job listing format
- **Solution**: Multiple selector patterns
- **Selectors**: `.job-vacancy`, `.job-item`

## Testing & Validation

### Run Test Suite

```bash
python test_playwright.py
```

### Expected Output

```
üß™ Playwright Scraper Test Suite
‚úÖ Playwright is available
üîç Testing category: software engineering
‚è±Ô∏è  Scraping completed in 12.34 seconds
üìä Found 8 jobs
```

## Deployment Considerations

### 1. **Memory Usage**

- Playwright uses ~100-200MB per browser instance
- Recommend 1GB+ RAM for production

### 2. **Docker Support**

```dockerfile
# Install system dependencies for Playwright
RUN apt-get update && apt-get install -y \
    libnss3 libatk-bridge2.0-0 libdrm2 libxkbcommon0 \
    libxcomposite1 libxdamage1 libxrandr2 libgbm1 \
    libxss1 libasound2
```

### 3. **Heroku Deployment**

- Add buildpack: `https://github.com/mxschmitt/heroku-playwright-buildpack`
- Set environment: `PLAYWRIGHT_BROWSERS_PATH=0`

## Monitoring & Optimization

### 1. **Success Rate Tracking**

```python
# Log scraping results
sources = {job['source'] for job in jobs}
logger.info(f"Success sources: {sources}")
```

### 2. **Performance Monitoring**

```python
# Track scraping times
start_time = time.time()
jobs = scrape_jobs_enhanced(interest)
elapsed = time.time() - start_time
logger.info(f"Scraping took {elapsed:.2f}s")
```

### 3. **Error Rate Analysis**

- Monitor 403 errors
- Track timeout rates
- Analyze selector failures

## Migration Path

### Phase 1: Install & Test

```bash
pip install playwright
playwright install
python test_playwright.py
```

### Phase 2: Update Bot

```python
# In bot.py, replace:
from scraper import scrape_jobs
# With:
from scraper_playwright import scrape_jobs_enhanced as scrape_jobs
```

### Phase 3: Monitor & Optimize

- Track success rates
- Adjust selectors if needed
- Monitor performance

## Troubleshooting

### Common Issues

1. **"Playwright not installed"**

   ```bash
   pip install playwright
   playwright install
   ```

2. **Browser launch failed**

   ```bash
   # Install system dependencies (Linux)
   sudo apt-get install libnss3 libatk-bridge2.0-0
   ```

3. **Timeout errors**

   - Check internet connection
   - Increase timeout values
   - Verify site accessibility

4. **No jobs found**
   - Sites may have changed selectors
   - Update CSS selectors in config
   - Check site structure manually

## Next Steps

1. **Install Playwright**: `pip install playwright && playwright install`
2. **Test Implementation**: `python test_playwright.py`
3. **Update Bot**: Replace scraper import in `bot.py`
4. **Monitor Results**: Track success rates and performance
5. **Optimize**: Adjust selectors and timeouts based on results

## Expected Results

With Playwright implementation, you should see:

- **Higher success rates**: 70-90% vs current 0%
- **Real job data**: From actual job sites instead of mock data
- **Better variety**: Jobs from multiple sources
- **Consistent performance**: Reliable scraping results

The investment in browser automation will significantly improve your job bot's effectiveness and user satisfaction! üöÄ
